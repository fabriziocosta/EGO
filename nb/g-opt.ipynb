{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:56.668650Z",
     "start_time": "2020-03-09T19:02:55.120897Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "import toolz as tz\n",
    "from eden.util import configure_logging\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "configure_logging(logger, verbosity=1)\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "HTML('<style>.container { width:95% !important; }</style><style>.output_png {display: table-cell;text-align: center;vertical-align: middle;}</style>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:56.701300Z",
     "start_time": "2020-03-09T19:02:56.671713Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:56.940434Z",
     "start_time": "2020-03-09T19:02:56.705477Z"
    }
   },
   "outputs": [],
   "source": [
    "from toolz import curry, pipe\n",
    "from eden_chem.io.pubchem import download\n",
    "from eden_chem.io.rdkitutils import sdf_to_nx\n",
    "\n",
    "download_active = curry(download)(active=True)\n",
    "download_inactive = curry(download)(active=False)\n",
    "\n",
    "def get_pos_graphs(assay_id): return pipe(assay_id, download_active, sdf_to_nx, list)\n",
    "def get_neg_graphs(assay_id): return pipe(assay_id, download_inactive, sdf_to_nx, list)\n",
    "\n",
    "from GraphOptimizer.load_utils import pre_process, _random_sample\n",
    "from eden_chem.io.pubchem import get_assay_description\n",
    "\n",
    "#assay_ids = ['624466','492992','463230','651741','743219','588350','492952','624249','463213','2631','651610']\n",
    "\n",
    "def load_PUBCHEM_data(assay_id, max_size=20):\n",
    "    configure_logging(logger, verbosity=2)\n",
    "    logger.debug('_'*80)\n",
    "    logger.debug('Dataset %s info:'%assay_id)\n",
    "    desc = get_assay_description(assay_id)\n",
    "    logging.debug('\\n%s'%desc)\n",
    "    # extract pos and neg graphs\n",
    "    all_pos_graphs, all_neg_graphs = get_pos_graphs(assay_id), get_neg_graphs(assay_id)\n",
    "    # remove too large and too small graphs and outliers\n",
    "    initial_max_size=2000\n",
    "    initial_max_size=max(initial_max_size,max_size)\n",
    "    args=dict(initial_max_size=initial_max_size, fraction_to_remove=.1, n_neighbors_for_outliers=9, remove_similar=False, max_size=max_size)\n",
    "    logging.debug('\\nPositive graphs')\n",
    "    pos_graphs = pre_process(all_pos_graphs, **args)\n",
    "    logging.debug('\\nNegative graphs')\n",
    "    neg_graphs = pre_process(all_neg_graphs, **args)\n",
    "    logger.debug('-'*80)\n",
    "    configure_logging(logger, verbosity=1)\n",
    "    return pos_graphs, neg_graphs\n",
    "\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from eden_chem.io.rdkitutils import nx_to_rdkit\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "from eden_chem.display.rdkitutils import nx_to_image\n",
    "\n",
    "def display_mol(graph, title, part_importance_estimator):\n",
    "    node_score_dict, edge_score_dict = part_importance_estimator.predict(graph)\n",
    "    weights = [node_score_dict[u] for u in graph.nodes()]\n",
    "    mol = nx_to_rdkit(graph)\n",
    "    fig = SimilarityMaps.GetSimilarityMapFromWeights(\n",
    "        mol, weights, size=(250, 250), alpha=0.075, contourLines=1, sigma=.03)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def draw_mols(graphs, titles=None, num=None, n_graphs_per_line=7):\n",
    "    \"\"\"draw_mols.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = [str(i) for i in range(len(graphs))]\n",
    "    if num is not None:\n",
    "        gs = graphs[:num]\n",
    "        titles = titles[:num]\n",
    "    else:\n",
    "        gs = graphs\n",
    "    for g,t in zip(gs,titles):\n",
    "        g.graph['id']=str(t)\n",
    "    try:\n",
    "        img = nx_to_image(gs, n_graphs_per_line=n_graphs_per_line, titles=titles)\n",
    "        display(img)\n",
    "    except Exception as e:\n",
    "        args = dict(layout='kk', colormap='Set1', vmin=0, vmax=1, vertex_size=80, edge_label=None, vertex_color_dict=colors, vertex_color='-label-', vertex_label=None,  ignore_for_layout='nesting')\n",
    "        draw_graph_set(gs, n_graphs_per_line=6, size=7, **args)\n",
    "        \n",
    "\n",
    "def display_ktop_mols(graphs, oracle_func, n_max=6):\n",
    "    scores = [oracle_func(g) for g in graphs]\n",
    "    ids = np.argsort(scores)[-n_max:]\n",
    "    best_graphs = [graphs[id] for id in ids]\n",
    "    best_scores = [scores[id] for id in ids]\n",
    "    distinct_best_scores = []\n",
    "    distinct_best_graphs = []\n",
    "    prev_score = None\n",
    "    counter = 0\n",
    "    distinct_counters = []\n",
    "    for best_graph, best_score in zip(best_graphs, best_scores):\n",
    "        if prev_score != best_score:\n",
    "            distinct_best_graphs.append(best_graph)\n",
    "            distinct_best_scores.append(best_score)\n",
    "            distinct_counters.append(counter)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        prev_score = best_score\n",
    "    titles = ['%.6f x %d'%(distinct_best_scores[i], distinct_counters[i+1]+1) for i in range(len(distinct_best_scores)-1) ]\n",
    "    titles += ['%.6f x %d'%(best_score,counter+1)]\n",
    "    draw_mols(distinct_best_graphs, titles=titles, n_graphs_per_line=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.004997Z",
     "start_time": "2020-03-09T19:02:56.945316Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.core.display import display\n",
    "from eden.display import draw_graph, draw_graph_set\n",
    "\n",
    "def select_unique(codes, fragments):\n",
    "    already_seen = set()\n",
    "    unique_codes=[]\n",
    "    unique_fragments=[]\n",
    "    code_counts = defaultdict(int)\n",
    "    for code, fragment in zip(codes, fragments):\n",
    "        if code not in already_seen:\n",
    "            unique_codes.append(code)\n",
    "            unique_fragments.append(fragment)\n",
    "            already_seen.add(code)\n",
    "        code_counts[code] += 1\n",
    "    return unique_codes, unique_fragments, code_counts\n",
    "\n",
    "def show_decomposition_graphs(graphs, decompose_funcs, preprocessors=None, show_labels=None, show_all=True):\n",
    "    feature_size, bitmask = set_feature_size(nbits=14)\n",
    "    encoding_func = make_encoder(decompose_funcs, preprocessors=preprocessors, bitmask=bitmask, seed=1)\n",
    "\n",
    "    from eden.display import map_labels_to_colors\n",
    "    colors = map_labels_to_colors(graphs)\n",
    "\n",
    "    for g in graphs:\n",
    "        print('_'*80)        \n",
    "        codes, fragments = encoding_func(g)\n",
    "        unique_codes, unique_fragments, code_counts = select_unique(codes, fragments)\n",
    "        titles = ['%d   #%d'%(id,code_counts[id]) for id in unique_codes]\n",
    "        for f,t in zip(unique_fragments, titles):\n",
    "            f.graph['id']=t\n",
    "        #titles = list(map(str, unique_codes))\n",
    "        print('%d unique components in %d fragments'%(len(unique_codes),len(codes)))\n",
    "        n_graphs_per_line=10\n",
    "        n_lines=4\n",
    "        size=2\n",
    "        if unique_fragments:\n",
    "            args = dict(layout='spring', colormap='Set1', vmin=0, vmax=1, vertex_size=80, edge_label=None, vertex_color_dict=colors, vertex_color='-label-', vertex_label=None,  ignore_for_layout='nesting')\n",
    "            draw_graph_set([g], n_graphs_per_line=n_graphs_per_line, size=7, **args)\n",
    "\n",
    "            if show_all is True:\n",
    "                draw_graph_set(unique_fragments, n_graphs_per_line=n_graphs_per_line, size=size, **args)\n",
    "            else:\n",
    "                draw_graph_set(unique_fragments[:n_graphs_per_line*n_lines], n_graphs_per_line=n_graphs_per_line, size=size, **args)\n",
    "            if show_labels:\n",
    "                draw_graph_set(unique_fragments[:n_graphs_per_line*n_lines], n_graphs_per_line=n_graphs_per_line, \n",
    "                           vertex_size=80, vertex_label='label', edge_label='label', size=size, ignore_for_layout='nesting')\n",
    "        else:\n",
    "            print('No fragments')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.046930Z",
     "start_time": "2020-03-09T19:02:57.007519Z"
    }
   },
   "outputs": [],
   "source": [
    "from eden.display import draw_graph, draw_graph_set, map_labels_to_colors\n",
    "def plot(graphs):\n",
    "    size=np.log(len(graphs[0]))+1\n",
    "    colors = map_labels_to_colors(graphs)\n",
    "    kwargs = dict(colormap='Set1', vmin=0, vmax=1, vertex_size=80, edge_label=None, vertex_color_dict=colors, vertex_color='_label_', vertex_label=None, ignore_for_layout='nesting', layout='spring')\n",
    "    draw_graph_set(graphs, n_graphs_per_line=5, size=size, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.105175Z",
     "start_time": "2020-03-09T19:02:57.049714Z"
    }
   },
   "outputs": [],
   "source": [
    "# create random graphs\n",
    "# give positive negative class to those with cycles larger than threshold\n",
    "# or with at least 2 cycles larger than threshold that share an edge \n",
    "\n",
    "import random\n",
    "\n",
    "def make_instance(length=20, alphabet_size=3, frac=.3, start_char=97):\n",
    "    n_frac=int(length*frac/(alphabet_size-1))\n",
    "\n",
    "    def make_char(i,start_char=97):\n",
    "        return chr(i+start_char)\n",
    "\n",
    "    def make_chars(i, dim, start_char=97):\n",
    "        return make_char(i,start_char)*dim\n",
    "\n",
    "    line=''\n",
    "    line += make_chars(0, length - n_frac*(alphabet_size-1), start_char)\n",
    "    for i in range(1, alphabet_size):\n",
    "        line += make_chars(i, n_frac, start_char)\n",
    "    line=list(line)\n",
    "    random.shuffle(line)\n",
    "    return ''.join(line)\n",
    "\n",
    "from toolz import curry \n",
    "\n",
    "\n",
    "@curry\n",
    "def random_path_graph(n):\n",
    "    return nx.path_graph(n)\n",
    "\n",
    "@curry\n",
    "def random_tree_graph(n):\n",
    "    return nx.random_tree(n)\n",
    "\n",
    "@curry\n",
    "def random_regular_graph(d, n):\n",
    "    return nx.random_regular_graph(d,n)\n",
    "\n",
    "@curry\n",
    "def random_degree_seq(n, dmax):\n",
    "    sequence = np.linspace(1, dmax,n).astype(int)\n",
    "    return nx.expected_degree_graph(sequence)\n",
    "\n",
    "@curry\n",
    "def random_dense_graph(n, m):\n",
    "    # a graph is chosen uniformly at random from the set of all graphs with n nodes and m edges\n",
    "    g = nx.dense_gnm_random_graph(n, m)\n",
    "    max_cc = max(nx.connected_components(g), key=lambda x: len(x))\n",
    "    g = nx.subgraph(g, max_cc)\n",
    "    return g\n",
    "\n",
    "@curry\n",
    "def make_graph(graph_generator, alphabet_size, frac):\n",
    "    G = graph_generator\n",
    "    labels = make_instance(length=len(G), alphabet_size=alphabet_size, frac=frac)\n",
    "    dict_labels = {i:str(l) for i,l in enumerate(labels)}\n",
    "    nx.set_node_attributes(G,dict_labels,'label')\n",
    "    nx.set_edge_attributes(G,'1','label')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.149458Z",
     "start_time": "2020-03-09T19:02:57.107834Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_sequence_data(target_graph, n_instances, diversity):\n",
    "    # extract sequence of labels\n",
    "    graphs = []\n",
    "    for n in range(n_instances):\n",
    "        seq = [target_graph.nodes[u]['label'] for u in target_graph.nodes()]\n",
    "        for i in range(diversity):\n",
    "            j = random.randint(1,len(target_graph))\n",
    "            seq = seq[j:][::-1] + seq[:j]\n",
    "        G=nx.path_graph(len(target_graph))\n",
    "        dict_labels = {i:str(l) for i,l in enumerate(seq)}\n",
    "        nx.set_node_attributes(G,dict_labels,'label')\n",
    "        nx.set_edge_attributes(G,'1','label')\n",
    "        graphs.append(G.copy())\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.230690Z",
     "start_time": "2020-03-09T19:02:57.152162Z"
    }
   },
   "outputs": [],
   "source": [
    "from ego.setup import *\n",
    "from ego.vectorize import vectorize as ego_vectorize\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "def ego_oracle_setup(target_graph, df=None, preproc=None):\n",
    "    target_graph_vec = ego_vectorize([target_graph], decomposition_funcs=df, preprocessors=preproc)\n",
    "    target_norm =  target_graph_vec.dot(target_graph_vec.T).A[0,0]\n",
    "    def oracle_func(g):\n",
    "        g_vec = ego_vectorize([g], decomposition_funcs=df, preprocessors=preproc)\n",
    "        g_norm =  g_vec.dot(g_vec.T).A[0,0]\n",
    "        scale_factor = np.sqrt(g_norm * target_norm)\n",
    "        score = g_vec.dot(target_graph_vec.T).A[0,0]/scale_factor\n",
    "        return score\n",
    "    return oracle_func\n",
    "\n",
    "import random\n",
    "def oracle_setup(target_graph, random_noise=0.05, include_structural_similarity=True):\n",
    "    df = do_decompose(decompose_cycles_and_non_cycles, decompose_neighborhood(radius=2))\n",
    "    preproc = preprocess_abstract_label(node_label='C', edge_label='1')\n",
    "    structural_oracle_func = ego_oracle_setup(target_graph, df, preproc)\n",
    "\n",
    "    df = do_decompose(decompose_nodes_and_edges)\n",
    "    preproc = None\n",
    "    compositional_oracle_func = ego_oracle_setup(target_graph, df, preproc)\n",
    "\n",
    "    df = do_decompose(decompose_path(length=2), decompose_neighborhood)\n",
    "    preproc = None\n",
    "    comp_and_struct_oracle_func = ego_oracle_setup(target_graph, df, preproc)\n",
    "\n",
    "    \n",
    "    target_size = len(target_graph)\n",
    "\n",
    "    def oracle_func(g, explain=False):\n",
    "        g_size = len(g)\n",
    "        size_similarity = max(0, 1 - abs(g_size - target_size)/float(target_size))\n",
    "        structural_similarity = structural_oracle_func(g)\n",
    "        composition_similarity = compositional_oracle_func(g)\n",
    "        comp_and_struct_similarity = comp_and_struct_oracle_func(g)\n",
    "        #score = min(size_similarity,structural_similarity,composition_similarity)\n",
    "        score = sp.stats.gmean([size_similarity,structural_similarity,composition_similarity,comp_and_struct_similarity])\n",
    "        noise = random.random()*random_noise\n",
    "        tot_score = score + noise \n",
    "        if explain:\n",
    "            return tot_score, score, size_similarity, structural_similarity, composition_similarity, comp_and_struct_similarity, noise\n",
    "        else:\n",
    "            return tot_score\n",
    "\n",
    "    return oracle_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.268086Z",
     "start_time": "2020-03-09T19:02:57.233210Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_k_best(graphs, oracle_func, num=100):\n",
    "    sorted_graphs = sorted(graphs, key=lambda g:oracle_func(g), reverse=True)\n",
    "    return sorted_graphs[:num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.329917Z",
     "start_time": "2020-03-09T19:02:57.270596Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import Rbf\n",
    "from eden.display.graph_layout import KKEmbedder\n",
    "\n",
    "def visualize_importance(g, part_importance_estimator, title=''):\n",
    "    g = nx.convert_node_labels_to_integers(g)\n",
    "    \n",
    "    node_imp_dict = part_importance_estimator.node_importance(g)\n",
    "\n",
    "    colors = map_labels_to_colors([g])\n",
    "    node_color = []\n",
    "    for u, d in g.nodes(data=True):\n",
    "        label = d.get('label', '.')\n",
    "        node_color.append(colors.get(label, 0))\n",
    "    pos = pos = KKEmbedder().transform(g)\n",
    "    X = np.array([pos[u] for u in sorted(pos.keys())])\n",
    "    y = np.array([node_imp_dict[u] for u in sorted(pos.keys())])\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = (x_max - x_min)/50  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    a, b = X.T\n",
    "    rbf = Rbf(a,b, y, epsilon=h*2, function='gaussian')\n",
    "    Z = rbf(xx, yy)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, 50, cmap='hot')\n",
    "\n",
    "    nodes = nx.draw_networkx_nodes(g, pos, node_size=90, linewidths=2, node_color=node_color, cmap='Set1')\n",
    "    nodes.set_edgecolor('k')\n",
    "    nx.draw_networkx_edges(g, pos, width=2, edge_color='grey')\n",
    "\n",
    "    a,b=X.T\n",
    "    plt.scatter(a,b,c=y, s=300, cmap='hot')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def paired_visualize_importance(g1,g2, part_importance_estimator, title1='', title2=''):\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    visualize_importance(g1, part_importance_estimator, title=title1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    visualize_importance(g2, part_importance_estimator, title=title2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.373789Z",
     "start_time": "2020-03-09T19:02:57.332757Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_grammar(grammar, n_max=9):\n",
    "    print(grammar)\n",
    "    cips_list = grammar.get()\n",
    "    for i, cips in enumerate(cips_list):\n",
    "        cip_list = [cip for interface, cip in cips if len(cip)>0]\n",
    "        interface_list = [interface for interface, cip in cips if len(interface)>0]\n",
    "        if interface_list:\n",
    "            print('-'*80)\n",
    "            print('interface %d/%d: interface size:%d  #cores:%d'%(i+1, len(cips_list),len(interface_list[0]),len(cips)))\n",
    "            draw_graph_set([interface_list[0]]+cip_list[:n_max], n_graphs_per_line=10, vertex_size=90, size=4, layout='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.481943Z",
     "start_time": "2020-03-09T19:02:57.376739Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import interpolate\n",
    "from eden.display import draw_graph, draw_graph_set, map_labels_to_colors\n",
    "\n",
    "    \n",
    "def draw_graphs(graphs, titles, n_graphs_per_line=6):\n",
    "    size=np.log(len(graphs[0]))+1\n",
    "    colors = map_labels_to_colors(graphs)\n",
    "    gs = graphs[:]\n",
    "    for g,t in zip(gs, titles): g.graph['id']=str(t)\n",
    "    kwargs = dict(colormap='Set1', vertex_size=80, edge_label=None, vertex_color_dict=colors, vertex_color='_label_', vertex_label=None, layout='KK')\n",
    "    draw_graph_set(gs, n_graphs_per_line=n_graphs_per_line, size=size, **kwargs)\n",
    "\n",
    "    \n",
    "def display_ktop_graphs(graphs, oracle_func, n_max=6):\n",
    "    scores = [oracle_func(g) for g in graphs]\n",
    "    ids = np.argsort(scores)[-n_max:]\n",
    "    best_graphs = [graphs[id] for id in ids]\n",
    "    best_scores = [scores[id] for id in ids]\n",
    "    distinct_best_scores = []\n",
    "    distinct_best_graphs = []\n",
    "    prev_score = None\n",
    "    counter = 0\n",
    "    distinct_counters = []\n",
    "    for best_graph, best_score in zip(best_graphs, best_scores):\n",
    "        if prev_score != best_score:\n",
    "            distinct_best_graphs.append(best_graph)\n",
    "            distinct_best_scores.append(best_score)\n",
    "            distinct_counters.append(counter)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        prev_score = best_score\n",
    "    titles = ['%.6f x %d'%(distinct_best_scores[i], distinct_counters[i+1]+1) for i in range(len(distinct_best_scores)-1) ]\n",
    "    titles += ['%.6f x %d'%(best_score,counter+1)]\n",
    "    draw_graphs(distinct_best_graphs, titles=titles, n_graphs_per_line=6)\n",
    "    \n",
    "    \n",
    "def display_graph_list(graphs, oracle_func, score_estimator, n_max, display_as_molecules=False):\n",
    "    gs = sorted(graphs, key=lambda g:oracle_func(g), reverse=True)[:n_max]\n",
    "    titles = []\n",
    "    for g in gs:\n",
    "        true_score = oracle_func(g)\n",
    "        pred_score = score_estimator.predict([g])[0]\n",
    "        titles.append('true:%.3f pred:%.3f  '%(true_score, pred_score))\n",
    "    if display_as_molecules:\n",
    "        draw_mols(gs, titles=titles, n_graphs_per_line=9)\n",
    "    else:\n",
    "        draw_graphs(gs, titles=titles, n_graphs_per_line=9)\n",
    "\n",
    "def smooth(x,y, sigma_fact=7):\n",
    "    sigma = (max(x)-min(x))/sigma_fact\n",
    "    xnew = np.linspace(min(x), max(x), 200)\n",
    "    gy = gaussian_filter1d(y, sigma)\n",
    "    f = interpolate.InterpolatedUnivariateSpline(x, gy)\n",
    "    ynew = f(xnew)\n",
    "    return xnew, ynew \n",
    "    \n",
    "def plot_status(estimated_mean_and_std_target, current_best, scores_list, num_oracle_queries, sigma_fact=7):\n",
    "    # target with variance\n",
    "    estimated_mean_and_std_target_array = np.array(estimated_mean_and_std_target)\n",
    "    target_means, target_stds = estimated_mean_and_std_target_array.T\n",
    "    fig = plt.figure(figsize=(17,5))\n",
    "    ax1 = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax1.fill_between(range(len(estimated_mean_and_std_target)), target_means+target_stds, target_means-target_stds, alpha=.1, color='steelblue')\n",
    "    ax1.fill_between(range(len(estimated_mean_and_std_target)), target_means+target_stds/10, target_means-target_stds/10, alpha=.1, color='steelblue')\n",
    "    ax1.fill_between(range(len(estimated_mean_and_std_target)), target_means+target_stds/100, target_means-target_stds/100, alpha=.1, color='steelblue')\n",
    "    ax1.plot(target_means, linestyle='dashed')\n",
    "    xx, m = smooth(range(len(target_means)),target_means,sigma_fact)\n",
    "    ax1.plot(xx, m, lw=5, color='steelblue', label='true target graph scored by predictor')\n",
    "    \n",
    "    # median and violinplot\n",
    "    #plt.violinplot(scores_list, range(len(scores_list)), points=60, widths=0.7, showmeans=True, showextrema=True, showmedians=True, bw_method=0.3)\n",
    "    medians = [np.median(scores) for scores in scores_list]\n",
    "    ax1.plot(medians, color='darkorange', lw=1, linestyle='dotted')\n",
    "    xx, m = smooth(range(len(medians)), medians, sigma_fact)\n",
    "    ax1.plot(xx, m, lw=3, linestyle='dashed', color='darkorange', label='median of generated graphs scored by oracle')\n",
    "\n",
    "    #current best\n",
    "    ax1.plot(current_best, color='darkorange', linestyle='dashed')\n",
    "    xx, m = smooth(range(len(current_best)), current_best,sigma_fact)\n",
    "    ax1.plot(xx, m, lw=5, color='darkorange', label='current opt graph scored by oracle')\n",
    "    ax1.legend()\n",
    "    y_low = max(0,min(min(medians), min(current_best)))\n",
    "    y_up = min(1,max(max(medians), max(current_best)))\n",
    "    ax1.set_ylim(y_low,y_up)\n",
    "    ax1.set_xlabel('num iteration')\n",
    "    ax1.set_ylabel('score')\n",
    "    ax1.grid()\n",
    "    \n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.plot(num_oracle_queries, linestyle='dotted', color='gray', alpha=.5, label='# queries to oracle')\n",
    "    ax2.set_ylabel('# queries')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "import time\n",
    "def make_monitor(target_graph, oracle_func, show_step=1, display_as_molecules=False):\n",
    "    history = []\n",
    "    estimated_mean_and_std_target=[]\n",
    "    current_best=[]\n",
    "    scores_list=[]  \n",
    "    duration = []\n",
    "    num_oracle_queries = []\n",
    "\n",
    "    def monitor(i, graphs, all_graphs, score_estimator):\n",
    "        num_oracle_queries.append(len(all_graphs))\n",
    "        history.extend(graphs[:])\n",
    "        mu, sigma = score_estimator.predict([target_graph]), score_estimator.predict_uncertainty([target_graph])\n",
    "        estimated_mean_and_std_target.append((mu[0],sigma[0]))\n",
    "        \n",
    "        true_scores = [oracle_func(g) for g in graphs]\n",
    "        pred_scores = score_estimator.predict(graphs)\n",
    "            \n",
    "        scores_list.append(true_scores)\n",
    "        best_score = max(true_scores)\n",
    "        best_graph = graphs[np.argmax(true_scores)]\n",
    "        print('< %.3f > best score after %d queries'%(best_score, len(all_graphs)))\n",
    "        tot_score, score, size_similarity, structural_similarity, composition_similarity, comp_and_struct_similarity, noise = oracle_func(best_graph, explain=True)\n",
    "        print('    score decomposition: %.3f = size:%.3f  structure:%.3f  composition:%.3f  comp_struct:%.3f'%(score, size_similarity, structural_similarity, composition_similarity, comp_and_struct_similarity))\n",
    "        current_best.append(best_score)\n",
    "        duration.append(time.clock())\n",
    "        if i>0 and (show_step==1 or i%show_step==0):\n",
    "            if len(estimated_mean_and_std_target)>5:\n",
    "                plot_status(estimated_mean_and_std_target,current_best, scores_list, num_oracle_queries, 5)\n",
    "\n",
    "            if len(duration)>2: print('%d) corr coeff true vs preds: %.3f  runtime:%.1f mins' % (i+1, np.corrcoef(true_scores,pred_scores)[0,1], (duration[-1]-duration[-2])/60))       \n",
    "            display_graph_list(graphs+[target_graph], oracle_func, score_estimator, n_max=9, display_as_molecules=display_as_molecules)\n",
    "            \n",
    "    return monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:02:57.559147Z",
     "start_time": "2020-03-09T19:02:57.484924Z"
    }
   },
   "outputs": [],
   "source": [
    "from ego.vectorize import hash_graph\n",
    "\n",
    "def make_variants(target_graph):\n",
    "    from ego.optimization.neighborhood_edge_swap import NeighborhoodEdgeSwap\n",
    "    nes = NeighborhoodEdgeSwap(n_edges=2, n_neighbors=10)\n",
    "    from ego.optimization.neighborhood_node_label_swap import NeighborhoodNodeLabelSwap\n",
    "    nns = NeighborhoodNodeLabelSwap(n_nodes=1, n_neighbors=10)\n",
    "    from ego.optimization.neighborhood_node_remove import NeighborhoodNodeRemove\n",
    "    nnr = NeighborhoodNodeRemove(n_neighbors=10, n_nodes=1)\n",
    "\n",
    "    gs = [target_graph]\n",
    "    transformations = [nes, nns] # [nes, nns, nnr]\n",
    "    for ne in transformations:\n",
    "        gs = [ng for g in gs for ng in ne.neighbors(g)]\n",
    "    return gs\n",
    "\n",
    "def remove_duplicates(graphs):\n",
    "    df = decompose_neighborhood(radius=2)\n",
    "    selected_graphs_dict = {hash_graph(\n",
    "        g, decomposition_funcs=df): g for g in graphs}\n",
    "    return list(selected_graphs_dict.values())\n",
    "\n",
    "def build_artificial_experiment(GRAPH_TYPE, n_init_instances, n_domain_instances, alphabet_size, diversity, max_score_threshold):\n",
    "    if GRAPH_TYPE == 'path':\n",
    "        graph_generator = random_path_graph(n=15)\n",
    "\n",
    "    if GRAPH_TYPE == 'tree':\n",
    "        graph_generator = random_tree_graph(n=18)\n",
    "    \n",
    "    if GRAPH_TYPE == 'degree':\n",
    "        n=12\n",
    "        dmax=4\n",
    "        graph_generator = random_degree_seq(n, dmax)\n",
    "        while nx.is_connected(graph_generator) is not True:\n",
    "            graph_generator = random_degree_seq(n, dmax)\n",
    "    \n",
    "    if GRAPH_TYPE == 'regular':\n",
    "        graph_generator = random_regular_graph(d=3, n=14)\n",
    "\n",
    "    if GRAPH_TYPE == 'dense':\n",
    "            graph_generator = random_dense_graph(n=15, m=38)\n",
    "            \n",
    "    target_graph = make_graph(graph_generator, alphabet_size=alphabet_size, frac=.5)\n",
    "    domain_graphs = make_variants(target_graph)\n",
    "    domain_graphs = domain_graphs[:n_domain_instances]\n",
    "    oracle_func = oracle_setup(target_graph, random_noise=0.0)\n",
    "    domain_graphs = [g for g in domain_graphs if oracle_func(g) < max_score_threshold]\n",
    "    domain_graphs = remove_duplicates(domain_graphs)\n",
    "    sorted_graphs = sorted(domain_graphs, key=lambda g:oracle_func(g), reverse=True) \n",
    "    half_size = int(n_init_instances/2)\n",
    "    rest_graphs = sorted_graphs[half_size:]\n",
    "    random.shuffle(rest_graphs)\n",
    "    init_graphs = sorted_graphs[:half_size] + rest_graphs[:half_size]\n",
    "    \n",
    "    return init_graphs, domain_graphs, oracle_func, target_graph\n",
    "\n",
    "def target_quality(target_graph, graphs, max_score_threshold, min_score_threshold):\n",
    "    # the quality of the target is measured as the fraction of graphs that are in a desired range of similarity \n",
    "    oracle_func = oracle_setup(target_graph, random_noise=0.0)\n",
    "    sel_graphs = [g for g in graphs if min_score_threshold < oracle_func(g) < max_score_threshold]\n",
    "    quality_score = len(sel_graphs)/float(len(graphs))\n",
    "    print('%.3f   '%(quality_score), end=\" \")\n",
    "    return quality_score\n",
    "\n",
    "def build_chemical_experiment(assay_id, n_init_instances, n_domain_instances, max_score_threshold, n_targets):\n",
    "    pos_graphs, neg_graphs = load_PUBCHEM_data(assay_id, max_size=n_domain_instances)\n",
    "    domain_graphs = pos_graphs+neg_graphs\n",
    "    domain_graphs = remove_duplicates(domain_graphs)\n",
    "    random.shuffle(domain_graphs)\n",
    "    \n",
    "    target_graph = max(domain_graphs[:n_targets], key=lambda g:target_quality(g, domain_graphs, max_score_threshold, max_score_threshold/1.5))\n",
    "    oracle_func = oracle_setup(target_graph, random_noise=0.0)\n",
    "\n",
    "    domain_graphs = [g for g in domain_graphs if oracle_func(g) < max_score_threshold]\n",
    "    sorted_graphs = sorted(domain_graphs, key=lambda g:oracle_func(g), reverse=True) \n",
    "    half_size = int(n_init_instances/2)\n",
    "    rest_graphs = sorted_graphs[half_size:]\n",
    "    random.shuffle(rest_graphs)\n",
    "    init_graphs = sorted_graphs[:half_size] + rest_graphs[:half_size]\n",
    "    return init_graphs, domain_graphs, oracle_func, target_graph\n",
    "\n",
    "def display_score_statistics(domain_graphs, oracle_func):\n",
    "    n_plots=5\n",
    "    plt.figure(figsize=(6,4))\n",
    "    scores = np.array([oracle_func(g) for g in domain_graphs])\n",
    "    plt.hist(scores, 30, density=True, alpha=.3)\n",
    "    plt.title('Scores')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:06:56.950421Z",
     "start_time": "2020-03-09T19:02:57.561865Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EXPERIMENT_TYPE = 'CHEMICAL'\n",
    "\n",
    "if EXPERIMENT_TYPE == 'ARTIFICIAL':\n",
    "    res = build_artificial_experiment(\n",
    "        GRAPH_TYPE='tree', # path  tree  degree  regular  dense\n",
    "        n_init_instances=10, \n",
    "        n_domain_instances=100,\n",
    "        alphabet_size=4, \n",
    "        diversity=2, \n",
    "        max_score_threshold=.8)\n",
    "    \n",
    "if EXPERIMENT_TYPE == 'CHEMICAL':\n",
    "    res = build_chemical_experiment(\n",
    "        assay_id='743219',  # assay_ids = ['624466','492992','463230','651741','743219','588350','492952','624249','463213','2631','651610']\n",
    "        n_init_instances=50, \n",
    "        n_domain_instances=300,\n",
    "        max_score_threshold=.8,\n",
    "        n_targets=2)\n",
    "\n",
    "init_graphs, domain_graphs, oracle_func, target_graph = res\n",
    "print('Generated %d graphs'%len(domain_graphs))\n",
    "display_score_statistics(domain_graphs, oracle_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:06:56.988004Z",
     "start_time": "2020-03-09T19:06:56.953386Z"
    }
   },
   "outputs": [],
   "source": [
    "# decomposition definition\n",
    "\n",
    "#decomposition_function = do_decompose(decompose_nodes_and_edges, decompose_path(min_len=2, max_len=3), decompose_neighborhood, decompose_neighborhood(radius=2), decompose_cycles)\n",
    "decomposition_function = do_decompose(decompose_nodes_and_edges, decompose_path(length=2), decompose_neighborhood, decompose_neighborhood(radius=2), decompose_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:06:57.026680Z",
     "start_time": "2020-03-09T19:06:56.990517Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DISPLAY_GRAMMAR=False\n",
    "\n",
    "if DISPLAY_GRAMMAR:\n",
    "    from graphlearn.lsgg_ego import lsgg_ego\n",
    "    grammar = lsgg_ego(decomposition_function=decomposition_function,\n",
    "                thickness=1,\n",
    "                filter_min_cip=1,\n",
    "                filter_min_interface=2,\n",
    "                nodelevel_radius_and_thickness=False)\n",
    "    grammar.fit(init_graphs)\n",
    "    plot_grammar(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:06:57.067605Z",
     "start_time": "2020-03-09T19:06:57.033619Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DISPLAY_DECOMPOSITION=False\n",
    "\n",
    "if DISPLAY_DECOMPOSITION:\n",
    "    print('This is how the target graph is decomposed:')\n",
    "    show_decomposition_graphs([target_graph], decompose_funcs=decomposition_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.148Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Best graphs in initial sample of %d'%len(init_graphs))\n",
    "if EXPERIMENT_TYPE == 'CHEMICAL':\n",
    "    display_ktop_mols(init_graphs+[target_graph], oracle_func, n_max=6)\n",
    "else:\n",
    "    display_ktop_graphs(init_graphs+[target_graph], oracle_func, n_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.152Z"
    }
   },
   "outputs": [],
   "source": [
    "from ego.optimization.neighborhood_node_label_mutation import NeighborhoodNodeLabelMutation\n",
    "nnlm = NeighborhoodNodeLabelMutation(n_nodes=5, n_neighbors=10)\n",
    "nnlm.fit(domain_graphs, None)\n",
    "gs = nnlm.neighbors(target_graph)\n",
    "gs = remove_duplicates(gs)\n",
    "display_ktop_mols(gs+[target_graph], oracle_func, n_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.155Z"
    }
   },
   "outputs": [],
   "source": [
    "from ego.optimization.neighborhood_edge_label_mutation import NeighborhoodEdgeLabelMutation\n",
    "nnlm = NeighborhoodEdgeLabelMutation(n_edges=5, n_neighbors=10)\n",
    "nnlm.fit(domain_graphs, None)\n",
    "gs = nnlm.neighbors(target_graph)\n",
    "gs = remove_duplicates(gs)\n",
    "display_ktop_mols(gs+[target_graph], oracle_func, n_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.159Z"
    }
   },
   "outputs": [],
   "source": [
    "from ego.optimization.neighborhood_edge_remove import NeighborhoodEdgeRemove\n",
    "nnlm = NeighborhoodEdgeRemove(n_edges=1, n_neighbors=None)\n",
    "nnlm.fit(domain_graphs, None)\n",
    "gs = nnlm.neighbors(target_graph)\n",
    "gs = remove_duplicates(gs)\n",
    "display_ktop_mols(gs+[target_graph], oracle_func, n_max=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.166Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from ego.optimization.optimize import optimizer_setup, optimize\n",
    "\n",
    "# performance monitor\n",
    "if EXPERIMENT_TYPE == 'CHEMICAL':\n",
    "    monitor = make_monitor(target_graph, oracle_func, display_as_molecules=True)\n",
    "else:\n",
    "    monitor = make_monitor(target_graph, oracle_func)\n",
    "\n",
    "from ego.setup import *\n",
    "decomposition_function = do_decompose(\n",
    "    decompose_nodes_and_edges, \n",
    "    decompose_path(length=2), \n",
    "    decompose_neighborhood, \n",
    "    decompose_neighborhood(radius=2), \n",
    "    decompose_neighborhood(radius=3), \n",
    "    decompose_cycles)\n",
    "\n",
    "decomposition_score_estimator = decomposition_function\n",
    "decomposition_fixed_grammar = decomposition_function\n",
    "decomposition_adaptive_grammar = decomposition_function\n",
    "\n",
    "neighborhood_estimators, score_estimator = optimizer_setup(\n",
    "    decomposition_score_estimator=decomposition_score_estimator,\n",
    "    use_UCB_estimator=False,\n",
    "    use_RandomForest_estimator=True,\n",
    "    use_Linear_estimator=False,\n",
    "    use_EI_estimator=False,\n",
    "    n_estimators=200,\n",
    "    exploration_vs_exploitation=0,\n",
    "    \n",
    "    use_edge_swapping=True,\n",
    "    n_neighbors_edge_swapping=None, n_edge_swapping=1,\n",
    "\n",
    "    use_node_label_swapping=True,\n",
    "    n_neighbors_node_label_swapping=None, n_node_label_swapping=1,\n",
    "\n",
    "    use_edge_label_swapping=False,\n",
    "    n_neighbors_edge_label_swapping=None, n_edge_label_swapping=1,\n",
    "\n",
    "    use_node_removal=False,\n",
    "    n_neighbors_node_removal=None, n_node_removal=1,\n",
    "    \n",
    "    use_edge_removal=True,\n",
    "    n_neighbors_edge_removal=None, n_edge_removal=1,\n",
    "\n",
    "    use_node_label_mutation=True,\n",
    "    n_neighbors_node_mutation=100, n_node_mutation=1,\n",
    "    \n",
    "    use_edge_label_mutation=False,\n",
    "    n_neighbors_edge_mutation=100, n_edge_mutation=1,\n",
    "    \n",
    "    use_fixed_grammar=False,\n",
    "    n_neighbors_fixed_grammar=None,\n",
    "    conservativeness_fixed_grammar=3,\n",
    "    context_size_fixed_grammar=1,\n",
    "    decomposition_fixed_grammar=decomposition_fixed_grammar,\n",
    "    domain_graphs_fixed_grammar=domain_graphs,\n",
    "\n",
    "    use_adaptive_grammar=True,\n",
    "    n_neighbors_adaptive_grammar=None,\n",
    "    conservativeness_adaptive_grammar=5,\n",
    "    context_size_adaptive_grammar=1,\n",
    "    part_size_adaptive_grammar=4,\n",
    "    decomposition_adaptive_grammar=decomposition_adaptive_grammar)\n",
    "\n",
    "graphs = init_graphs[:]\n",
    "graphs = optimize(\n",
    "    graphs, \n",
    "    oracle_func, \n",
    "    n_iter=100, \n",
    "    n_queries_to_oracle_per_iter=200,\n",
    "    frac_instances_to_remove_per_iter=.5,\n",
    "    sample_size_to_perturb=4, \n",
    "    n_steps_driven_by_estimator=1,\n",
    "    sample_size_for_grammars=40,\n",
    "    neighborhood_estimators=neighborhood_estimators,\n",
    "    score_estimator=score_estimator, \n",
    "    monitor=monitor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-09T19:02:55.170Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Final: best sinthesized graphs in set of size %d'%len(graphs))\n",
    "if EXPERIMENT_TYPE == 'CHEMICAL':\n",
    "    display_ktop_mols(graphs+[target_graph], oracle_func, n_max=6*2)\n",
    "else:\n",
    "    display_ktop_graphs(graphs+[target_graph], oracle_func, n_max=6*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
